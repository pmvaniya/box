{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from json import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of Great Expectations\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the \n"
     ]
    }
   ],
   "source": [
    "text = open(\"GreatExpectations.txt\", \"r\").read()\n",
    "print(text[:264])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '#', '$', '%', '&', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ê', 'ô', '—', '‘', '’', '“', '”', '•', '™', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "unwanted = ['\\t', '\\n', '!', '#', '$', '%', '&', '(', ')', '*', ',', '-', '.', '/', ':', ';', '?', '[', ']', '_', 'ê', 'ô', '—', '‘', '’', '“', '”', '•', '™', '\\ufeff']\n",
    "\n",
    "# we remove all the unwanted characters for this particular example, we would have left the punctuation marks intact if it were the actual llm\n",
    "for char in unwanted:\n",
    "    text = text.replace(char, \" \")\n",
    "\n",
    "# remove all the extra whitespaces\n",
    "while \"  \" in text:\n",
    "    text = text.replace(\"  \", \" \")\n",
    "\n",
    "print(sorted(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Project Gutenberg eBook of Great Expectations This ebook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever You may copy it give it away or re use it under the terms of the Project Gutenberg License included with this ebook or online at www gutenberg org If you are not located in the United States you will have to check the laws of the country where you are located before using this eBook Title Great\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, 'A': 11, 'B': 12, 'C': 13, 'D': 14, 'E': 15, 'F': 16, 'G': 17, 'H': 18, 'I': 19, 'J': 20, 'K': 21, 'L': 22, 'M': 23, 'N': 24, 'O': 25, 'P': 26, 'Q': 27, 'R': 28, 'S': 29, 'T': 30, 'U': 31, 'V': 32, 'W': 33, 'X': 34, 'Y': 35, 'Z': 36, 'a': 37, 'b': 38, 'c': 39, 'd': 40, 'e': 41, 'f': 42, 'g': 43, 'h': 44, 'i': 45, 'j': 46, 'k': 47, 'l': 48, 'm': 49, 'n': 50, 'o': 51, 'p': 52, 'q': 53, 'r': 54, 's': 55, 't': 56, 'u': 57, 'v': 58, 'w': 59, 'x': 60, 'y': 61, 'z': 62}\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(list(set(text)))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "stoi = {s: i for i, s in enumerate(vocab)}\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "\n",
    "print(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of xs: 970256\n",
      "xs: tensor([ 0, 30, 44,  ..., 51, 47, 55])\n",
      "ys: tensor([30, 44, 41,  ..., 47, 55,  0])\n"
     ]
    }
   ],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for x, y in zip(text, text[1:]):\n",
    "    xs.append(stoi[x])\n",
    "    ys.append(stoi[y])\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "print(\"length of xs:\", xs.nelement())\n",
    "print(\"xs:\", xs)\n",
    "print(\"ys:\", ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.528252124786377"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(64)\n",
    "\n",
    "# initial weights\n",
    "W = torch.randn((vocab_size, vocab_size), generator=g, requires_grad=True)\n",
    "\n",
    "# forward pass\n",
    "xenc = F.one_hot(xs, num_classes=vocab_size).float()  # input for nn\n",
    "logits = xenc @ W  # log-counts\n",
    "counts = logits.exp()  # soft-max\n",
    "probs = counts / counts.sum(1, keepdim=True)  # probabilies by normalization\n",
    "loss = -probs[torch.arange(len(ys)), ys].log().mean()\n",
    "\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None  # set gradient to 0\n",
    "loss.backward()\n",
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52728271484375\n",
      "2.9421470165252686\n",
      "2.6841366291046143\n",
      "2.573885202407837\n",
      "2.5157883167266846\n",
      "final loss: 2.480990171432495\n"
     ]
    }
   ],
   "source": [
    "epochs = 250\n",
    "\n",
    "for i in range(epochs):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=vocab_size).float()\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    loss = -probs[torch.arange(len(ys)), ys].log().mean()\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -10 * W.grad\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(loss.item())\n",
    "\n",
    "print(\"final loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rt th an t teQT0ou d Ajxt ahaXfcorb4n9llAisit t I uthon uI hal Ig pamerver an d n y wathay f ld wamyofld Phed ihandy trre b8ante mele SCqGme he IPYritha9V yute h t cothed hiwalu hesYELG5kVTbLCRs ben fe id wimftot fof heenN4ngJkeqmeder h GKd s havuKxf s li\n"
     ]
    }
   ],
   "source": [
    "# finally, generate some text\n",
    "\n",
    "output = []\n",
    "x = stoi['a']\n",
    "\n",
    "for i in range(256):\n",
    "    xenc = F.one_hot(torch.tensor([x]), num_classes=vocab_size).float()\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    p = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "    x = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    output.append(itos[x])\n",
    "\n",
    "print(\"\".join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save token ids to a json file\n",
    "\n",
    "with open(\"tokens.json\", \"w\") as outfile: \n",
    "    dump(stoi, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81918"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the weights to a file\n",
    "\n",
    "weights = []\n",
    "outtext = \"\"\n",
    "\n",
    "for i in range(len(W)):\n",
    "    weights.append([])\n",
    "\n",
    "    for j in range(len(W[i])):\n",
    "        weights[i].append(str(W[i][j].item()))\n",
    "\n",
    "    outtext += \", \".join(weights[i])\n",
    "    outtext += \"\\n\"\n",
    "\n",
    "open(\"weights.txt\", \"w\").write(outtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
