{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of Great Expectations\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the \n"
     ]
    }
   ],
   "source": [
    "text = open(\"GreatExpectations.txt\", \"r\").read()\n",
    "print(text[:264])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '#', '$', '%', '&', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ê', 'ô', '—', '‘', '’', '“', '”', '•', '™', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "unwanted = ['\\t', '\\n', '!', '#', '$', '%', '&', '(', ')', '*', ',', '-', '.', '/', ':', ';', '?', '[', ']', '_', 'ê', 'ô', '—', '‘', '’', '“', '”', '•', '™', '\\ufeff']\n",
    "\n",
    "# we remove all the unwanted characters for this particular example, we would have left the punctuation marks intact if it were the actual llm\n",
    "for char in unwanted:\n",
    "    text = text.replace(char, \" \")\n",
    "\n",
    "# remove all the extra whitespaces\n",
    "while \"  \" in text:\n",
    "    text = text.replace(\"  \", \" \")\n",
    "\n",
    "print(sorted(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Project Gutenberg eBook of Great Expectations This ebook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever You may copy it give it away or re use it under the terms of the Project Gutenberg License included with this ebook or online at www gutenberg org If you are not located in the United States you will have to check the laws of the country where you are located before using this eBook Title Great\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, 'A': 11, 'B': 12, 'C': 13, 'D': 14, 'E': 15, 'F': 16, 'G': 17, 'H': 18, 'I': 19, 'J': 20, 'K': 21, 'L': 22, 'M': 23, 'N': 24, 'O': 25, 'P': 26, 'Q': 27, 'R': 28, 'S': 29, 'T': 30, 'U': 31, 'V': 32, 'W': 33, 'X': 34, 'Y': 35, 'Z': 36, 'a': 37, 'b': 38, 'c': 39, 'd': 40, 'e': 41, 'f': 42, 'g': 43, 'h': 44, 'i': 45, 'j': 46, 'k': 47, 'l': 48, 'm': 49, 'n': 50, 'o': 51, 'p': 52, 'q': 53, 'r': 54, 's': 55, 't': 56, 'u': 57, 'v': 58, 'w': 59, 'x': 60, 'y': 61, 'z': 62}\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(list(set(text)))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "stoi = {s: i for i, s in enumerate(vocab)}\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "\n",
    "print(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of xs: 970256\n",
      "xs: tensor([ 0, 30, 44,  ..., 51, 47, 55])\n",
      "ys: tensor([30, 44, 41,  ..., 47, 55,  0])\n"
     ]
    }
   ],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for x, y in zip(text, text[1:]):\n",
    "    xs.append(stoi[x])\n",
    "    ys.append(stoi[y])\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "print(\"length of xs:\", xs.nelement())\n",
    "print(\"xs:\", xs)\n",
    "print(\"ys:\", ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.528252124786377"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(64)\n",
    "\n",
    "# initial weights\n",
    "W = torch.randn((vocab_size, vocab_size), generator=g, requires_grad=True)\n",
    "\n",
    "# forward pass\n",
    "xenc = F.one_hot(xs, num_classes=vocab_size).float()  # input for nn\n",
    "logits = xenc @ W  # log-counts\n",
    "counts = logits.exp()  # soft-max\n",
    "probs = counts / counts.sum(1, keepdim=True)  # probabilies by normalization\n",
    "loss = -probs[torch.arange(len(ys)), ys].log().mean()\n",
    "\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None  # set gradient to 0\n",
    "loss.backward()\n",
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52728271484375\n",
      "3.768092393875122\n",
      "3.3884150981903076\n",
      "3.1796138286590576\n",
      "3.0421338081359863\n",
      "2.9421470165252686\n",
      "2.8661739826202393\n",
      "2.806469678878784\n",
      "2.7581021785736084\n",
      "2.7179768085479736\n",
      "final loss: 2.6872785091400146\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for i in range(epochs):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=vocab_size).float()\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    loss = -probs[torch.arange(len(ys)), ys].log().mean()\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -10 * W.grad\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(loss.item())\n",
    "\n",
    "print(\"final loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rt t0WBCqm827QT0ouI hAjx1qUhaXfcorbLn9llAiscrSd I uLMpn 2Dkpar Yg pangSver an d n y wR6J27f2 ld wainVH37TPheJCihandy1Scre b8ante me6DnSCqGme he IPYritha9V yute het cothed hiwUCw hesYELG5kVTbLCRs ben fHLLQy iIftWPFZWf heenN4ngJkeqmMOer hUGKd s hkvuKxf06MD5\n"
     ]
    }
   ],
   "source": [
    "# finally, generate some text\n",
    "\n",
    "output = []\n",
    "x = stoi['a']\n",
    "\n",
    "for i in range(256):\n",
    "    xenc = F.one_hot(torch.tensor([x]), num_classes=vocab_size).float()\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    p = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "    x = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    output.append(itos[x])\n",
    "\n",
    "print(\"\".join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81927"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the weights to a file\n",
    "\n",
    "weights = []\n",
    "outtext = \"\"\n",
    "\n",
    "for i in range(len(W)):\n",
    "    weights.append([])\n",
    "\n",
    "    for j in range(len(W[i])):\n",
    "        weights[i].append(str(W[i][j].item()))\n",
    "\n",
    "    outtext += \", \".join(weights[i])\n",
    "    outtext += \"\\n\"\n",
    "\n",
    "open(\"weights.txt\", \"w\").write(outtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
